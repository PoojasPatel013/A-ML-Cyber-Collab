{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8729154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training with data from: data\n",
      "\n",
      "Training combined CNN model...\n",
      "Loading and combining data from all files...\n",
      "\n",
      "Processing file: data\\cyberattack.csv\n",
      "Found target column: Flow Bytes/s in data\\cyberattack.csv\n",
      "Column values: [4000000.       110091.7431   230769.2308   352941.1765    11741.68297]...\n",
      "\n",
      "Features found in data\\cyberattack.csv:\n",
      "Total features: 79\n",
      "First 5 features: [' Destination Port', ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets', 'Total Length of Fwd Packets']\n",
      "Last 5 features: ['Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min', ' Label']\n",
      "Number of unique classes: 91644\n",
      "Label distribution: [2357    1    1 ...    4   13    3]\n",
      "Warning: Large number of classes found (91644). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=91643\n",
      "Unique labels: 91644\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (100000, 78)\n",
      "Combined y shape: (100000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 100000\n",
      "Number of unique classes: 95106\n",
      "Label distribution: [863   1   1 ...   5   3   6]\n",
      "Warning: Large number of classes found (95106). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=95105\n",
      "Unique labels: 95106\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (200000, 78)\n",
      "Combined y shape: (200000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 200000\n",
      "Number of unique classes: 69669\n",
      "Label distribution: [   1    4 7422 ...   13   38    7]\n",
      "Warning: Large number of classes found (69669). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=69668\n",
      "Unique labels: 69669\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (300000, 78)\n",
      "Combined y shape: (300000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 300000\n",
      "Number of unique classes: 12575\n",
      "Label distribution: [  1  11   5 ...   4 171   2]\n",
      "Warning: Large number of classes found (12575). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=12574\n",
      "Unique labels: 12575\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (400000, 78)\n",
      "Combined y shape: (400000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 400000\n",
      "Number of unique classes: 21870\n",
      "Label distribution: [  2  10   1 ...   4 144   7]\n",
      "Warning: Large number of classes found (21870). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=21869\n",
      "Unique labels: 21870\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (500000, 78)\n",
      "Combined y shape: (500000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 500000\n",
      "Number of unique classes: 68017\n",
      "Label distribution: [   4    1 7686 ...    4   69   13]\n",
      "Warning: Large number of classes found (68017). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=68016\n",
      "Unique labels: 68017\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (600000, 78)\n",
      "Combined y shape: (600000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 600000\n",
      "Number of unique classes: 69020\n",
      "Label distribution: [   4 8937    1 ...    4   37   14]\n",
      "Warning: Large number of classes found (69020). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=69019\n",
      "Unique labels: 69020\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (700000, 78)\n",
      "Combined y shape: (700000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 700000\n",
      "Number of unique classes: 79653\n",
      "Label distribution: [   3 6939    1 ...    2   77   17]\n",
      "Warning: Large number of classes found (79653). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=79652\n",
      "Unique labels: 79653\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (800000, 78)\n",
      "Combined y shape: (800000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 800000\n",
      "Number of unique classes: 72382\n",
      "Label distribution: [    2 10722     1 ...     1    75    11]\n",
      "Warning: Large number of classes found (72382). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=72381\n",
      "Unique labels: 72382\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (900000, 78)\n",
      "Combined y shape: (900000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 900000\n",
      "Number of unique classes: 79084\n",
      "Label distribution: [   2 5789    1 ...   25   44    9]\n",
      "Warning: Large number of classes found (79084). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=79083\n",
      "Unique labels: 79084\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (1000000, 78)\n",
      "Combined y shape: (1000000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 1000000\n",
      "Number of unique classes: 60473\n",
      "Label distribution: [    2 13033     1 ...     3    76    11]\n",
      "Warning: Large number of classes found (60473). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=60472\n",
      "Unique labels: 60473\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (1100000, 78)\n",
      "Combined y shape: (1100000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 1100000\n",
      "Number of unique classes: 48507\n",
      "Label distribution: [16149     1     1 ...     1    79    15]\n",
      "Warning: Large number of classes found (48507). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=48506\n",
      "Unique labels: 48507\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (1200000, 78)\n",
      "Combined y shape: (1200000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 1200000\n",
      "Number of unique classes: 64688\n",
      "Label distribution: [    2 11447     1 ...     9    48     4]\n",
      "Warning: Large number of classes found (64688). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=64687\n",
      "Unique labels: 64688\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (1300000, 78)\n",
      "Combined y shape: (1300000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 1300000\n",
      "Number of unique classes: 47286\n",
      "Label distribution: [   1 9235    1 ...    4   75   11]\n",
      "Warning: Large number of classes found (47286). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=47285\n",
      "Unique labels: 47286\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (1400000, 78)\n",
      "Combined y shape: (1400000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 1400000\n",
      "Number of unique classes: 46166\n",
      "Label distribution: [6824    1    1 ...    5   84    5]\n",
      "Warning: Large number of classes found (46166). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=46165\n",
      "Unique labels: 46166\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (1500000, 78)\n",
      "Combined y shape: (1500000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 1500000\n",
      "Number of unique classes: 67444\n",
      "Label distribution: [ 1  5  1 ...  3 75  8]\n",
      "Warning: Large number of classes found (67444). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=67443\n",
      "Unique labels: 67444\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (1600000, 78)\n",
      "Combined y shape: (1600000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 1600000\n",
      "Number of unique classes: 69010\n",
      "Label distribution: [    4 11098     3 ...    11    50    22]\n",
      "Warning: Large number of classes found (69010). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=69009\n",
      "Unique labels: 69010\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (1700000, 78)\n",
      "Combined y shape: (1700000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 1700000\n",
      "Number of unique classes: 71683\n",
      "Label distribution: [18260     1     1 ...     4    17    42]\n",
      "Warning: Large number of classes found (71683). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=71682\n",
      "Unique labels: 71683\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (1800000, 78)\n",
      "Combined y shape: (1800000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 1800000\n",
      "Number of unique classes: 71888\n",
      "Label distribution: [20439     1     1 ...     9    22    37]\n",
      "Warning: Large number of classes found (71888). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=71887\n",
      "Unique labels: 71888\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (1900000, 78)\n",
      "Combined y shape: (1900000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 1900000\n",
      "Number of unique classes: 65150\n",
      "Label distribution: [22701     1     1 ...     1    20    41]\n",
      "Warning: Large number of classes found (65150). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=65149\n",
      "Unique labels: 65150\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (2000000, 78)\n",
      "Combined y shape: (2000000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 2000000\n",
      "Number of unique classes: 46922\n",
      "Label distribution: [33681     1     1 ...     2     1    54]\n",
      "Warning: Large number of classes found (46922). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=46921\n",
      "Unique labels: 46922\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (2100000, 78)\n",
      "Combined y shape: (2100000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 2100000\n",
      "Number of unique classes: 67555\n",
      "Label distribution: [    4 18018     1 ...     5    47    27]\n",
      "Warning: Large number of classes found (67555). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=67554\n",
      "Unique labels: 67555\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (2200000, 78)\n",
      "Combined y shape: (2200000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 2200000\n",
      "Number of unique classes: 76292\n",
      "Label distribution: [22018     1     1 ...     1     7   283]\n",
      "Warning: Large number of classes found (76292). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=76291\n",
      "Unique labels: 76292\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (2300000, 78)\n",
      "Combined y shape: (2300000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 2300000\n",
      "Number of unique classes: 73703\n",
      "Label distribution: [    1 25388     1 ...     3     2   431]\n",
      "Warning: Large number of classes found (73703). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=73702\n",
      "Unique labels: 73703\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (2400000, 78)\n",
      "Combined y shape: (2400000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 2400000\n",
      "Number of unique classes: 65831\n",
      "Label distribution: [25179     1     1 ...    19    34   251]\n",
      "Warning: Large number of classes found (65831). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=65830\n",
      "Unique labels: 65831\n",
      "X array shape: (100000, 78)\n",
      "y array shape: (100000,)\n",
      "Combined X shape: (2500000, 78)\n",
      "Combined y shape: (2500000,)\n",
      "Processed chunk with 100000 samples\n",
      "Current memory usage: 31.20 MB\n",
      "Total samples so far: 2500000\n",
      "Number of unique classes: 78659\n",
      "Label distribution: [   3 5475    1 ...   16   65   18]\n",
      "Warning: Large number of classes found (78659). This might indicate a problem with the target column.\n",
      "Label value range: min=0, max=78658\n",
      "Unique labels: 78659\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class CombinedCyberThreatDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.all_files = glob.glob(os.path.join(data_dir, \"*.csv\"))\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.num_classes = None\n",
    "        self._load_and_combine_data()\n",
    "        \n",
    "    def get_num_classes(self):\n",
    "        \"\"\"Get the number of unique classes in the dataset\"\"\"\n",
    "        if self.y is not None:\n",
    "            self.num_classes = len(np.unique(self.y))\n",
    "            return self.num_classes\n",
    "        return None\n",
    "        \n",
    "    def _load_and_combine_data(self):\n",
    "        \"\"\"Load and combine data from files efficiently\"\"\"\n",
    "        print(\"Loading and combining data from all files...\")\n",
    "        \n",
    "        # First pass: Collect all unique features\n",
    "        all_features = []\n",
    "        chunk_size = 100000  # Process in chunks to handle large files\n",
    "        \n",
    "        # Process each file and combine immediately\n",
    "        for current_file in self.all_files:\n",
    "            print(f\"\\nProcessing file: {current_file}\")\n",
    "            try:\n",
    "                # Process file in chunks\n",
    "                first_chunk = True\n",
    "                for chunk in pd.read_csv(current_file, chunksize=chunk_size):\n",
    "                    if first_chunk:\n",
    "                        # Detect target column\n",
    "                        target_col = None\n",
    "                        patterns = [\n",
    "                            'label', 'prediction', 'type', 'phishing', 'attack_type', 'attack',\n",
    "                            'class', 'result', 'target', 'y', 'outcome', 'category'\n",
    "                        ]\n",
    "                        \n",
    "                        # Convert all column names to lowercase\n",
    "                        lower_cols = [col.lower() for col in chunk.columns]\n",
    "                        \n",
    "                        # Try exact matches first\n",
    "                        for pattern in patterns:\n",
    "                            if pattern in lower_cols:\n",
    "                                target_col = chunk.columns[lower_cols.index(pattern)]\n",
    "                                break\n",
    "                        \n",
    "                        # If not found, try partial matches\n",
    "                        if not target_col:\n",
    "                            for col, lower_col in zip(chunk.columns, lower_cols):\n",
    "                                if any(pattern in lower_col for pattern in patterns):\n",
    "                                    target_col = col\n",
    "                                    break\n",
    "                        \n",
    "                        # If still not found, try to find the column with the least unique values\n",
    "                        if not target_col:\n",
    "                            min_unique = float('inf')\n",
    "                            for col in chunk.columns:\n",
    "                                try:\n",
    "                                    unique_count = chunk[col].nunique()\n",
    "                                    if unique_count < min_unique:\n",
    "                                        min_unique = unique_count\n",
    "                                        target_col = col\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Warning: Error checking unique values for {col}: {e}\")\n",
    "                        \n",
    "                        if not target_col:\n",
    "                            print(f\"Warning: No target column found in {current_file}\")\n",
    "                            break\n",
    "                        \n",
    "                        print(f\"Found target column: {target_col} in {current_file}\")\n",
    "                        print(f\"Column values: {chunk[target_col].unique()[:5]}...\")\n",
    "                        \n",
    "                        # Add features from this file\n",
    "                        if not all_features:  # Initialize with first file's features\n",
    "                            all_features = chunk.columns.tolist()\n",
    "                        else:\n",
    "                            # Add new features from this file\n",
    "                            new_features = set(chunk.columns) - set(all_features)\n",
    "                            all_features.extend(sorted(new_features))\n",
    "                        \n",
    "                        first_chunk = False\n",
    "                        \n",
    "                        # Print feature stats\n",
    "                        print(f\"\\nFeatures found in {current_file}:\")\n",
    "                        print(f\"Total features: {len(chunk.columns)}\")\n",
    "                        print(f\"First 5 features: {chunk.columns[:5].tolist()}\")\n",
    "                        print(f\"Last 5 features: {chunk.columns[-5:].tolist()}\")\n",
    "                        \n",
    "                    # Create aligned DataFrame with all features\n",
    "                    df_aligned = pd.DataFrame(columns=all_features)\n",
    "                    \n",
    "                    # Fill with data where available, 0 where not\n",
    "                    for col in all_features:\n",
    "                        if col in chunk.columns:\n",
    "                            df_aligned[col] = chunk[col]\n",
    "                        else:\n",
    "                            df_aligned[col] = 0\n",
    "                    \n",
    "                    # Process features\n",
    "                    X = df_aligned.drop(target_col, axis=1)\n",
    "                    y = chunk[target_col]\n",
    "                    \n",
    "                    # Handle categorical features\n",
    "                    categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "                    for col in categorical_cols:\n",
    "                        X[col] = pd.factorize(X[col])[0]\n",
    "                    \n",
    "                    # Convert to numeric and use float32\n",
    "                    X = X.astype('float32').fillna(0)\n",
    "                    \n",
    "                    # Convert labels using LabelEncoder\n",
    "                    le = LabelEncoder()\n",
    "                    y = le.fit_transform(y)\n",
    "                    \n",
    "                    # Validate feature shape\n",
    "                    if X.shape[1] != len(all_features) - 1:\n",
    "                        raise ValueError(f\"Feature shape mismatch in {current_file}: Expected {len(all_features) - 1}, got {X.shape[1]}\")\n",
    "                    \n",
    "                    # Validate label values\n",
    "                    if y.min() < 0:  # Labels should always be non-negative\n",
    "                        raise ValueError(f\"Negative label values found: min={y.min()}\")\n",
    "                    \n",
    "                    # Print label statistics\n",
    "                    num_classes = len(np.unique(y))\n",
    "                    print(f\"Number of unique classes: {num_classes}\")\n",
    "                    print(f\"Label distribution: {np.bincount(y)}\")\n",
    "                    \n",
    "                    if num_classes > 1000:  # If too many classes, raise warning\n",
    "                        print(f\"Warning: Large number of classes found ({num_classes}). This might indicate a problem with the target column.\")\n",
    "                    \n",
    "                    # Convert to numpy arrays immediately\n",
    "                    X_array = X.to_numpy(dtype=np.float32)\n",
    "                    y_array = np.array(y, dtype=np.int32)\n",
    "                    \n",
    "                    # Print label statistics\n",
    "                    print(f\"Label value range: min={y.min()}, max={y.max()}\")\n",
    "                    print(f\"Unique labels: {len(np.unique(y))}\")\n",
    "                    \n",
    "                    # If this is the first chunk, initialize arrays\n",
    "                    if self.X is None:\n",
    "                        self.X = X_array\n",
    "                        self.y = y_array\n",
    "                    else:\n",
    "                        # Append to existing arrays\n",
    "                        self.X = np.vstack([self.X, X_array])\n",
    "                        self.y = np.concatenate([self.y, y_array])\n",
    "                        \n",
    "                    # Print array shapes for debugging\n",
    "                    print(f\"X array shape: {X_array.shape}\")\n",
    "                    print(f\"y array shape: {y_array.shape}\")\n",
    "                    print(f\"Combined X shape: {self.X.shape if self.X is not None else 'None'}\")\n",
    "                    print(f\"Combined y shape: {self.y.shape if self.y is not None else 'None'}\")\n",
    "                    \n",
    "                    print(f\"Processed chunk with {len(X_array)} samples\")\n",
    "                    print(f\"Current memory usage: {X_array.nbytes / 1e6:.2f} MB\")\n",
    "                    print(f\"Total samples so far: {len(self.X)}\")\n",
    "                    \n",
    "                    # Clean up\n",
    "                    del X, y, X_array, y_array, df_aligned\n",
    "                    gc.collect()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing {current_file}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if self.X is not None:\n",
    "            print(f\"\\nCombined dataset stats:\")\n",
    "            print(f\"Total samples: {len(self.X)}\")\n",
    "            print(f\"Feature shape: {self.X.shape}\")\n",
    "            print(f\"Label shape: {self.y.shape}\")\n",
    "            print(f\"Unique labels: {np.unique(self.y)}\")\n",
    "            print(f\"Total memory usage: {self.X.nbytes / 1e6:.2f} MB\")\n",
    "        else:\n",
    "            raise ValueError(\"No valid data loaded from files\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "            y = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "            \n",
    "            return X, y\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item: {e}\")\n",
    "            raise\n",
    "\n",
    "class CombinedCyberThreatCNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(CombinedCyberThreatCNN, self).__init__()\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(1, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        \n",
    "        # Calculate output size\n",
    "        self.output_size = self._get_output_size(input_size)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.output_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def _get_output_size(self, input_size):\n",
    "        x = torch.randn(1, 1, input_size)\n",
    "        x = self.feature_extractor(x)\n",
    "        return x.view(x.size(0), -1).size(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def train_combined_model(data_dir):\n",
    "    try:\n",
    "        print(\"\\nTraining combined CNN model...\")\n",
    "        \n",
    "        # Create dataset and dataloader\n",
    "        dataset = CombinedCyberThreatDataset(data_dir)\n",
    "        dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        # Get first batch to determine input size and number of classes\n",
    "        X_sample, y_sample = next(iter(dataloader))\n",
    "        input_size = X_sample.shape[1]  \n",
    "        num_classes = len(torch.unique(y_sample))\n",
    "        \n",
    "        # Initialize model, loss, and optimizer\n",
    "        model = CombinedCyberThreatCNN(input_size, num_classes)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Create save directory\n",
    "        save_dir = 'models_combined'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Training loop\n",
    "        num_epochs = 50\n",
    "        best_accuracy = 0\n",
    "        \n",
    "        print(f\"\\nStarting training with input size: {input_size}, num_classes: {num_classes}\")\n",
    "        print(f\"Total samples: {len(dataset)}\")\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for i, (X, y) in enumerate(dataloader):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += y.size(0)\n",
    "                correct += (predicted == y).sum().item()\n",
    "                \n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(dataloader)}], Loss: {running_loss:.4f}')\n",
    "            \n",
    "            train_acc = 100 * correct / total\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "            \n",
    "            # Save best model\n",
    "            if train_acc > best_accuracy:\n",
    "                best_accuracy = train_acc\n",
    "                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                model_file = os.path.join(save_dir, f'combined_cnn_model_{timestamp}.pth')\n",
    "                torch.save(model.state_dict(), model_file)\n",
    "                print(f\"Saved best model with accuracy: {train_acc:.2f}%\")\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training combined model: {e}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Create necessary directories\n",
    "        os.makedirs('models_combined', exist_ok=True)\n",
    "        \n",
    "        # Train combined model\n",
    "        data_dir = 'data'\n",
    "        print(f\"\\nStarting training with data from: {data_dir}\")\n",
    "        model = train_combined_model(data_dir)\n",
    "        \n",
    "        if model:\n",
    "            print(\"\\nSuccessfully trained combined CNN model\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6afba52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
